{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tXjbE7gG4MpJYvTEYAZ_Io-toL5shHYD",
      "authorship_tag": "ABX9TyMh3VooJ76El6yOW4M1Rezi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydydydydydy/Colab/blob/main/ex04_%EA%B0%9C_%EA%B3%A0%EC%96%91%EC%9D%B4_%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN(Convolution Neural Network)\n",
        "  - 이미지 학습 가능(2차원의 데이터도 학습)\n",
        "  - 데이터에서 특징을 추출하고 추출된 특징을 기반으로 학습\n",
        "    - 이미지의 크기, 방향 등에 크게 관여하지 않는다\n",
        "    "
      ],
      "metadata": {
        "id": "yafAgYF30Js4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/dogs_vs_cats_small\n",
        " # 데이터 경로지정\n",
        " train_dir = '/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/dogs_vs_cats_small/train'\n",
        " valid_dir = '/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/dogs_vs_cats_small/validation'"
      ],
      "metadata": {
        "id": "9Zm0T_pc9Hg2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 변수에 이미지 파일 전부다 합치기\n",
        "# 픽셀값( 0 ~ 255 / 정수 ) (변경) --> ( 0 ~ 1 까지의 / 실수값 )\n",
        "## 1. 숫자 크기 줄이기 > 연산량 감소\n",
        "## 2. 분산(값이 분포해있는 범) 줄이기 > 연산의 오류 줄어듦\n",
        "# 이미지 크기 맞춰주기 (150,150)\n",
        "# 라벨링\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "N3IzZTdX9Hq8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 픽셀값 변경 기능 만들기\n",
        "# 묵시적 형변환 하기\n",
        "## 프로그래밍에서 연산상에서 타입이 변경되도록 하기\n",
        "generator = ImageDataGenerator(rescale = 1./255) # 1. = 1.0"
      ],
      "metadata": {
        "id": "a7hBEJgQ9Hxu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 변수에 이밎 파일 전부다 합치기\n",
        "# 이미지 크기 동일하게 만들어주기\n",
        "# 라벨링\n",
        "train_generator = generator.flow_from_directory(\n",
        "    directory = train_dir, # train 이미지 경로, 변환할 이미지\n",
        "    target_size = (150,150),  # 변환할 이미지 크기\n",
        "    batch_size = 100,  # 한번에 변환할 이미지 갯수\n",
        "    class_mode = 'binary'  # 라벨링 방법, 다중분류 : categorical\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8oGcZkH9H4o",
        "outputId": "81442382-8493-4e98-c4d6-59f08beb5d23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = generator.flow_from_directory(\n",
        "    directory = valid_dir, # train 이미지 경로, 변환할 이미지\n",
        "    target_size = (150,150),  # 변환할 이미지 크기\n",
        "    batch_size = 100,  # 한번에 변환할 이미지 갯수\n",
        "    class_mode = 'binary'  # 라벨링 방법, 다중분류 : categorical\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tblD18H9H8z",
        "outputId": "12ea85cb-1022-4b1e-b8e3-964ed579de5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 설계\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
      ],
      "metadata": {
        "id": "-LwvJWA-9IDT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 모델 생성\n",
        "# 건물 토대 설계\n",
        "model1 = Sequential()\n",
        "\n",
        "# 입력층\n",
        "model1.add(Conv2D(  # 특징 찾기\n",
        "    filters = 32, # 찾을 특징의 갯수\n",
        "    kernel_size = (3,3),  # 특징의 크기\n",
        "    input_shape = (150, 150,3),  # 입력 데이터의 모양(3 = RGB) # 0 : 검은색, 255 : 흰색\n",
        "    activation = 'relu'\n",
        "))\n",
        "\n",
        "model1.add(MaxPool2D( # 특징이 아닌 부분 삭제하기\n",
        "    pool_size = (2,2) # 기준 크기에서 1개의 특징만 가져오기 / 4개중에 한 개 사용하기\n",
        "))\n",
        "\n",
        "\n",
        "model1.add(Conv2D(  # 특징 찾기\n",
        "    filters = 32, # 찾을 특징의 갯수\n",
        "    kernel_size = (3,3),  # 특징의 크기\n",
        "    activation = 'relu'\n",
        "))\n",
        "\n",
        "model1.add(MaxPool2D( # 특징이 아닌 부분 삭제하기\n",
        "    pool_size = (2,2) # 기준 크기에서 1개의 특징만 가져오기 / 4개중에 한 개 사용하기\n",
        "))\n",
        "\n",
        "################# 특징 추출부 끝 ####################\n",
        "model1.add(Flatten())  # 특징추출부와 분류부를 이어주는 역할\n",
        "################# 분류 분석 시작 ####################\n",
        "model1.add(Dense(units = 32, activation = 'relu'))\n",
        "\n",
        "# 출력층\n",
        "model1.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "35ncmPke9IXK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 방법 설정\n",
        "model1.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "RBdKnBfq9IbT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(\n",
        "    train_generator, # 학습 데이터(X_train, y_train이 합쳐져 있다)\n",
        "    epochs = 20,\n",
        "    validation_data = valid_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR5EeKYr9IgJ",
        "outputId": "69245ccc-6ffa-44ce-d53f-a669cb0f9686"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 793s 40s/step - loss: 0.8241 - accuracy: 0.5040 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 9s 439ms/step - loss: 0.6783 - accuracy: 0.5620 - val_loss: 0.6628 - val_accuracy: 0.5680\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 0.6515 - accuracy: 0.5890 - val_loss: 0.6520 - val_accuracy: 0.5580\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 9s 447ms/step - loss: 0.6205 - accuracy: 0.6785 - val_loss: 0.6512 - val_accuracy: 0.5940\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 9s 446ms/step - loss: 0.5695 - accuracy: 0.7145 - val_loss: 0.6206 - val_accuracy: 0.6690\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 11s 537ms/step - loss: 0.5159 - accuracy: 0.7540 - val_loss: 0.5942 - val_accuracy: 0.6850\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 9s 449ms/step - loss: 0.4523 - accuracy: 0.7980 - val_loss: 0.5812 - val_accuracy: 0.6940\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 9s 435ms/step - loss: 0.3968 - accuracy: 0.8405 - val_loss: 0.5779 - val_accuracy: 0.7090\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 8s 407ms/step - loss: 0.3187 - accuracy: 0.8760 - val_loss: 0.5789 - val_accuracy: 0.7220\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 9s 437ms/step - loss: 0.2731 - accuracy: 0.8990 - val_loss: 0.6560 - val_accuracy: 0.7020\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 9s 443ms/step - loss: 0.2244 - accuracy: 0.9235 - val_loss: 0.6540 - val_accuracy: 0.7130\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 8s 412ms/step - loss: 0.1807 - accuracy: 0.9440 - val_loss: 0.7128 - val_accuracy: 0.7020\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 0.1333 - accuracy: 0.9650 - val_loss: 0.7145 - val_accuracy: 0.7160\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 9s 436ms/step - loss: 0.1182 - accuracy: 0.9680 - val_loss: 0.7598 - val_accuracy: 0.7020\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 9s 456ms/step - loss: 0.0839 - accuracy: 0.9850 - val_loss: 0.8567 - val_accuracy: 0.7130\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 8s 410ms/step - loss: 0.0585 - accuracy: 0.9905 - val_loss: 0.8943 - val_accuracy: 0.7170\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 9s 444ms/step - loss: 0.0437 - accuracy: 0.9960 - val_loss: 0.9314 - val_accuracy: 0.7120\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 9s 432ms/step - loss: 0.0333 - accuracy: 0.9985 - val_loss: 0.9739 - val_accuracy: 0.7170\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 0.0263 - accuracy: 0.9990 - val_loss: 1.0220 - val_accuracy: 0.7120\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 9s 438ms/step - loss: 0.0213 - accuracy: 0.9995 - val_loss: 1.0993 - val_accuracy: 0.7060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a39581127d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EfTdKEG79IkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xoGKtZ19Inv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7i5Ypbfe9IrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YoeKN0XL9IvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8EhKKjxH9IyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}